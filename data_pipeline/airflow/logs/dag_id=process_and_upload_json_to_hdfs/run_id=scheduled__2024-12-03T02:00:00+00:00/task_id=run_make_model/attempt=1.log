[2024-12-03T12:06:23.119+0900] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-12-03T12:06:23.129+0900] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: process_and_upload_json_to_hdfs.run_make_model scheduled__2024-12-03T02:00:00+00:00 [queued]>
[2024-12-03T12:06:23.136+0900] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: process_and_upload_json_to_hdfs.run_make_model scheduled__2024-12-03T02:00:00+00:00 [queued]>
[2024-12-03T12:06:23.137+0900] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2024-12-03T12:06:23.152+0900] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): run_make_model> on 2024-12-03 02:00:00+00:00
[2024-12-03T12:06:23.155+0900] {standard_task_runner.py:72} INFO - Started process 327558 to run task
[2024-12-03T12:06:23.159+0900] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'process_and_upload_json_to_hdfs', 'run_make_model', 'scheduled__2024-12-03T02:00:00+00:00', '--job-id', '444', '--raw', '--subdir', 'DAGS_FOLDER/data_to_hdfs.py', '--cfg-path', '/tmp/tmp38pp36z5']
[2024-12-03T12:06:23.160+0900] {standard_task_runner.py:105} INFO - Job 444: Subtask run_make_model
[2024-12-03T12:06:23.193+0900] {task_command.py:467} INFO - Running <TaskInstance: process_and_upload_json_to_hdfs.run_make_model scheduled__2024-12-03T02:00:00+00:00 [running]> on host MN
[2024-12-03T12:06:23.261+0900] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='process_and_upload_json_to_hdfs' AIRFLOW_CTX_TASK_ID='run_make_model' AIRFLOW_CTX_EXECUTION_DATE='2024-12-03T02:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-12-03T02:00:00+00:00'
[2024-12-03T12:06:23.262+0900] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-03T12:06:23.276+0900] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2024-12-03T12:06:23.277+0900] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', '/laewon/spark/bin/spark-submit --master yarn --deploy-mode cluster /laewon/Riot/make_model.py']
[2024-12-03T12:06:23.283+0900] {subprocess.py:99} INFO - Output:
[2024-12-03T12:06:25.534+0900] {subprocess.py:106} INFO - 24/12/03 12:06:25 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at MN/192.168.4.7:8032
[2024-12-03T12:06:26.230+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 INFO Configuration: resource-types.xml not found
[2024-12-03T12:06:26.230+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 INFO ResourceUtils: Unable to find 'resource-types.xml'.
[2024-12-03T12:06:26.245+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (819200 MB per container)
[2024-12-03T12:06:26.246+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 INFO Client: Will allocate AM container, with 1408 MB memory including 384 MB overhead
[2024-12-03T12:06:26.246+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 INFO Client: Setting up container launch context for our AM
[2024-12-03T12:06:26.250+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 INFO Client: Setting up the launch environment for our AM container
[2024-12-03T12:06:26.261+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 INFO Client: Preparing resources for our AM container
[2024-12-03T12:06:26.296+0900] {subprocess.py:106} INFO - 24/12/03 12:06:26 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
[2024-12-03T12:06:29.169+0900] {subprocess.py:106} INFO - 24/12/03 12:06:29 INFO Client: Uploading resource file:/tmp/spark-215cb5b8-4ce3-4175-8854-bddbeabe70ec/__spark_libs__10354950054537216955.zip -> hdfs://MN:9000/user/dke/.sparkStaging/application_1733127595631_0022/__spark_libs__10354950054537216955.zip
[2024-12-03T12:07:03.613+0900] {subprocess.py:106} INFO - 24/12/03 12:07:03 INFO Client: Uploading resource file:/laewon/Riot/make_model.py -> hdfs://MN:9000/user/dke/.sparkStaging/application_1733127595631_0022/make_model.py
[2024-12-03T12:07:03.646+0900] {subprocess.py:106} INFO - 24/12/03 12:07:03 INFO Client: Uploading resource file:/laewon/spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip -> hdfs://MN:9000/user/dke/.sparkStaging/application_1733127595631_0022/pyspark.zip
[2024-12-03T12:07:03.883+0900] {subprocess.py:106} INFO - 24/12/03 12:07:03 INFO Client: Uploading resource file:/laewon/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip -> hdfs://MN:9000/user/dke/.sparkStaging/application_1733127595631_0022/py4j-0.10.9.7-src.zip
[2024-12-03T12:07:04.084+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO Client: Uploading resource file:/tmp/spark-215cb5b8-4ce3-4175-8854-bddbeabe70ec/__spark_conf__17423164563754671528.zip -> hdfs://MN:9000/user/dke/.sparkStaging/application_1733127595631_0022/__spark_conf__.zip
[2024-12-03T12:07:04.163+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO SecurityManager: Changing view acls to: dke
[2024-12-03T12:07:04.164+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO SecurityManager: Changing modify acls to: dke
[2024-12-03T12:07:04.164+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO SecurityManager: Changing view acls groups to:
[2024-12-03T12:07:04.164+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO SecurityManager: Changing modify acls groups to:
[2024-12-03T12:07:04.165+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: dke; groups with view permissions: EMPTY; users with modify permissions: dke; groups with modify permissions: EMPTY
[2024-12-03T12:07:04.201+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO Client: Submitting application application_1733127595631_0022 to ResourceManager
[2024-12-03T12:07:04.245+0900] {subprocess.py:106} INFO - 24/12/03 12:07:04 INFO YarnClientImpl: Submitted application application_1733127595631_0022
[2024-12-03T12:07:05.248+0900] {subprocess.py:106} INFO - 24/12/03 12:07:05 INFO Client: Application report for application_1733127595631_0022 (state: ACCEPTED)
[2024-12-03T12:07:05.252+0900] {subprocess.py:106} INFO - 24/12/03 12:07:05 INFO Client:
[2024-12-03T12:07:05.252+0900] {subprocess.py:106} INFO - 	 client token: N/A
[2024-12-03T12:07:05.252+0900] {subprocess.py:106} INFO - 	 diagnostics: AM container is launched, waiting for AM container to Register with RM
[2024-12-03T12:07:05.253+0900] {subprocess.py:106} INFO - 	 ApplicationMaster host: N/A
[2024-12-03T12:07:05.253+0900] {subprocess.py:106} INFO - 	 ApplicationMaster RPC port: -1
[2024-12-03T12:07:05.253+0900] {subprocess.py:106} INFO - 	 queue: root.default
[2024-12-03T12:07:05.254+0900] {subprocess.py:106} INFO - 	 start time: 1733195224224
[2024-12-03T12:07:05.254+0900] {subprocess.py:106} INFO - 	 final status: UNDEFINED
[2024-12-03T12:07:05.254+0900] {subprocess.py:106} INFO - 	 tracking URL: http://MN:8088/proxy/application_1733127595631_0022/
[2024-12-03T12:07:05.255+0900] {subprocess.py:106} INFO - 	 user: dke
[2024-12-03T12:07:12.262+0900] {subprocess.py:106} INFO - 24/12/03 12:07:12 INFO Client: Application report for application_1733127595631_0022 (state: RUNNING)
[2024-12-03T12:07:12.262+0900] {subprocess.py:106} INFO - 24/12/03 12:07:12 INFO Client:
[2024-12-03T12:07:12.262+0900] {subprocess.py:106} INFO - 	 client token: N/A
[2024-12-03T12:07:12.263+0900] {subprocess.py:106} INFO - 	 diagnostics: N/A
[2024-12-03T12:07:12.263+0900] {subprocess.py:106} INFO - 	 ApplicationMaster host: SN02
[2024-12-03T12:07:12.263+0900] {subprocess.py:106} INFO - 	 ApplicationMaster RPC port: 34741
[2024-12-03T12:07:12.263+0900] {subprocess.py:106} INFO - 	 queue: root.default
[2024-12-03T12:07:12.263+0900] {subprocess.py:106} INFO - 	 start time: 1733195224224
[2024-12-03T12:07:12.264+0900] {subprocess.py:106} INFO - 	 final status: UNDEFINED
[2024-12-03T12:07:12.264+0900] {subprocess.py:106} INFO - 	 tracking URL: http://MN:8088/proxy/application_1733127595631_0022/
[2024-12-03T12:07:12.265+0900] {subprocess.py:106} INFO - 	 user: dke
[2024-12-03T12:07:42.301+0900] {subprocess.py:106} INFO - 24/12/03 12:07:42 INFO Client: Application report for application_1733127595631_0022 (state: ACCEPTED)
[2024-12-03T12:07:42.302+0900] {subprocess.py:106} INFO - 24/12/03 12:07:42 INFO Client:
[2024-12-03T12:07:42.302+0900] {subprocess.py:106} INFO - 	 client token: N/A
[2024-12-03T12:07:42.302+0900] {subprocess.py:106} INFO - 	 diagnostics: AM container is launched, waiting for AM container to Register with RM
[2024-12-03T12:07:42.303+0900] {subprocess.py:106} INFO - 	 ApplicationMaster host: N/A
[2024-12-03T12:07:42.303+0900] {subprocess.py:106} INFO - 	 ApplicationMaster RPC port: -1
[2024-12-03T12:07:42.303+0900] {subprocess.py:106} INFO - 	 queue: root.default
[2024-12-03T12:07:42.303+0900] {subprocess.py:106} INFO - 	 start time: 1733195224224
[2024-12-03T12:07:42.304+0900] {subprocess.py:106} INFO - 	 final status: UNDEFINED
[2024-12-03T12:07:42.304+0900] {subprocess.py:106} INFO - 	 tracking URL: http://MN:8088/proxy/application_1733127595631_0022/
[2024-12-03T12:07:42.304+0900] {subprocess.py:106} INFO - 	 user: dke
[2024-12-03T12:07:47.308+0900] {subprocess.py:106} INFO - 24/12/03 12:07:47 INFO Client: Application report for application_1733127595631_0022 (state: RUNNING)
[2024-12-03T12:07:47.309+0900] {subprocess.py:106} INFO - 24/12/03 12:07:47 INFO Client:
[2024-12-03T12:07:47.309+0900] {subprocess.py:106} INFO - 	 client token: N/A
[2024-12-03T12:07:47.310+0900] {subprocess.py:106} INFO - 	 diagnostics: N/A
[2024-12-03T12:07:47.310+0900] {subprocess.py:106} INFO - 	 ApplicationMaster host: SN01
[2024-12-03T12:07:47.310+0900] {subprocess.py:106} INFO - 	 ApplicationMaster RPC port: 44689
[2024-12-03T12:07:47.311+0900] {subprocess.py:106} INFO - 	 queue: root.default
[2024-12-03T12:07:47.311+0900] {subprocess.py:106} INFO - 	 start time: 1733195224224
[2024-12-03T12:07:47.311+0900] {subprocess.py:106} INFO - 	 final status: UNDEFINED
[2024-12-03T12:07:47.312+0900] {subprocess.py:106} INFO - 	 tracking URL: http://MN:8088/proxy/application_1733127595631_0022/
[2024-12-03T12:07:47.312+0900] {subprocess.py:106} INFO - 	 user: dke
[2024-12-03T12:08:08.335+0900] {subprocess.py:106} INFO - 24/12/03 12:08:08 INFO Client: Application report for application_1733127595631_0022 (state: FINISHED)
[2024-12-03T12:08:08.335+0900] {subprocess.py:106} INFO - 24/12/03 12:08:08 INFO Client:
[2024-12-03T12:08:08.335+0900] {subprocess.py:106} INFO - 	 client token: N/A
[2024-12-03T12:08:08.336+0900] {subprocess.py:106} INFO - 	 diagnostics: User application exited with status 1
[2024-12-03T12:08:08.336+0900] {subprocess.py:106} INFO - 	 ApplicationMaster host: SN01
[2024-12-03T12:08:08.336+0900] {subprocess.py:106} INFO - 	 ApplicationMaster RPC port: 44689
[2024-12-03T12:08:08.336+0900] {subprocess.py:106} INFO - 	 queue: root.default
[2024-12-03T12:08:08.337+0900] {subprocess.py:106} INFO - 	 start time: 1733195224224
[2024-12-03T12:08:08.337+0900] {subprocess.py:106} INFO - 	 final status: FAILED
[2024-12-03T12:08:08.337+0900] {subprocess.py:106} INFO - 	 tracking URL: http://MN:8088/proxy/application_1733127595631_0022/
[2024-12-03T12:08:08.337+0900] {subprocess.py:106} INFO - 	 user: dke
[2024-12-03T12:08:08.342+0900] {subprocess.py:106} INFO - 24/12/03 12:08:08 ERROR Client: Application diagnostics message: User application exited with status 1
[2024-12-03T12:08:08.343+0900] {subprocess.py:106} INFO - Exception in thread "main" org.apache.spark.SparkException: Application application_1733127595631_0022 finished with failed status
[2024-12-03T12:08:08.344+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.yarn.Client.run(Client.scala:1309)
[2024-12-03T12:08:08.344+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1742)
[2024-12-03T12:08:08.344+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1029)
[2024-12-03T12:08:08.345+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)
[2024-12-03T12:08:08.345+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)
[2024-12-03T12:08:08.345+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)
[2024-12-03T12:08:08.346+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)
[2024-12-03T12:08:08.346+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)
[2024-12-03T12:08:08.346+0900] {subprocess.py:106} INFO - 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
[2024-12-03T12:08:08.347+0900] {subprocess.py:106} INFO - 24/12/03 12:08:08 INFO ShutdownHookManager: Shutdown hook called
[2024-12-03T12:08:08.348+0900] {subprocess.py:106} INFO - 24/12/03 12:08:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-215cb5b8-4ce3-4175-8854-bddbeabe70ec
[2024-12-03T12:08:08.350+0900] {subprocess.py:106} INFO - 24/12/03 12:08:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-45118fd7-10fd-4bd3-9047-7deb619e63b2
[2024-12-03T12:08:08.703+0900] {subprocess.py:110} INFO - Command exited with return code 1
[2024-12-03T12:08:08.712+0900] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-12-03T12:08:08.718+0900] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=process_and_upload_json_to_hdfs, task_id=run_make_model, run_id=scheduled__2024-12-03T02:00:00+00:00, execution_date=20241203T020000, start_date=20241203T030623, end_date=20241203T030808
[2024-12-03T12:08:08.737+0900] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-03T12:08:08.738+0900] {standard_task_runner.py:124} ERROR - Failed to execute job 444 for task run_make_model (Bash command failed. The command returned a non-zero exit code 1.; 327558)
Traceback (most recent call last):
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
  File "/laewon/airflow_test/py_venv/lib/python3.8/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-12-03T12:08:08.784+0900] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2024-12-03T12:08:08.799+0900] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-12-03T12:08:08.800+0900] {local_task_job_runner.py:245} INFO - ::endgroup::
